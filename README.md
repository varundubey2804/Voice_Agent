oice-Enabled RAG Insurance Agent: Veena
Veena is a sophisticated, voice-enabled conversational AI that acts as a friendly insurance agent for ValuEnable Life Insurance.
Her primary mission: engage customers about their policy renewals â€” all in real-time, with Agentic RAG and a local Ollama LLM.

ğŸš€ Overview
Veena is a local-first backend service that enables real-time voice conversations with:

Speech-to-text transcription

Reasoning & memory with LangChain ReAct Agent

Retrieval-Augmented Generation (RAG)

Persona-driven replies

Natural speech output

WebSocket frontend integration

âœ¨ Core Features
ğŸ§ Real-Time Voice Conversation â€“ Captures microphone input, transcribes, and responds instantly.

ğŸ§  Agentic AI Core â€“ LangChainâ€™s ReAct agent for reasoning, tool use, and memory.

ğŸ“š RAG Search â€“ Access internal policy/customer data via FAISS vector store.

ğŸ”’ Fully Local â€“ Runs on local Ollama instance (e.g., LLaMA 3).

ğŸ—£ Natural Speech Output â€“ gTTS + Pygame for smooth voice playback.

ğŸ”Œ WebSocket Backend â€“ Connect from React, Vue, or any WebSocket client.

ğŸ›  Architecture
mermaid
Copy
Edit
flowchart LR
    A[ğŸ¤ Microphone Input] --> B[ASR: Faster-Whisper]
    B --> C[LangChain Agent: Veena Persona]
    C -->|Needs Info| D[ğŸ” FAISS RAG Search]
    C -->|Generates Reply| E[Local Ollama LLM]
    E --> F[gTTS Text-to-Speech]
    F --> G[ğŸ”Š Audio Playback]
    C --> H[ğŸ”Œ WebSocket Updates to Frontend]
ğŸ“‚ Project Structure
graphql
Copy
Edit
.
â”œâ”€â”€ app.py                # Main backend app (audio loop + WebSocket server)
â”œâ”€â”€ agentic_rag.py        # LangChain agent, RAG tool, memory, and persona
â”œâ”€â”€ index_documents.py    # Build FAISS vector index from knowledge base
â”œâ”€â”€ voice_service.py      # Text-to-speech + audio playback
â”œâ”€â”€ Requestollama.py      # Test Ollama API connection
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ rag_docs/             # Knowledge base text files
â”œâ”€â”€ faiss_rag.index       # Generated FAISS vector store
â””â”€â”€ .gitignore
âš™ï¸ Setup & Installation
1ï¸âƒ£ Prerequisites
Python 3.8+

Ollama installed & running locally

Working microphone

2ï¸âƒ£ Installation Steps
bash
Copy
Edit
# Clone repo
git clone <repo_url>
cd <repo_folder>

# Create virtual environment
python -m venv venv
# Windows
venv\Scripts\activate
# macOS/Linux
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
3ï¸âƒ£ Pull Ollama Models
bash
Copy
Edit
ollama pull llama3
ollama pull nomic-embed-text
4ï¸âƒ£ Prepare Knowledge Base
bash
Copy
Edit
# Create rag_docs folder and add your .txt files
mkdir rag_docs
5ï¸âƒ£ Build FAISS Vector Index
bash
Copy
Edit
python index_documents.py
6ï¸âƒ£ Run Backend
bash
Copy
Edit
python app.py
âœ… You should see:

arduino
Copy
Edit
Audio recording started...
WebSocket server running on ws://localhost:8765
ğŸ›  Configuration
Component	File	Setting
LLM & Embeddings	agentic_rag.py	LLM_MODEL_NAME, EMBED_MODEL_NAME
RAG Chunking	index_documents.py	Chunk size & overlap
Persona Behavior	agentic_rag.py	Persona prompt
Audio Parameters	app.py	DEFAULT_CHUNK_LENGTH

ğŸ§ª Utility Script
Test Ollama Connection

bash
Copy
Edit
python Requestollama.py
ğŸ“œ License
MIT License â€“ free to use, modify, and distribute.

ğŸ’¡ Tip
To integrate with a custom frontend, connect to:

arduino
Copy
Edit
ws://localhost:8765
and listen for:

user_message

agent_response

speaking_started

speaking_ended

